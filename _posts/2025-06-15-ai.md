---
layout: post
title: AI
date: 2025-06-15 23:55 -0500
author: nooneswarup
categories: [AI]
tags: [AI, ML]  
---

1. Data Modalities:
	1. Text: PDFs, DOCX, APIs, CSVs, DataFrames
	2. vision: images, videos
	3. speech: audio
	4. multi-modal: any of the above
2. Understanding Unstructured Data
	1. 80% of real-world data is unstructured
	2. Computers understand only numbers, so:
	3. Use document loaders
	4. Chunk data
	5. Generate embeddings → convert into vectors
	6. Store vectors in a Vector DB (or use NumPy for small-scale tasks)
	7. data → embedding model → vector → vector DB
	8. query → embedding → similarity search → retrieve answer
3. Preprocessing Steps: (NLTK, SpaCY)
	1. Text normalization
	2. POS tagging (noun/verb detection)
	3. Stopword removal
	4. Stemming & Lemmatization
	5. Named Entity Recognition (NER)
4. Vectorization Techniques
	1. Basic: Bag of Words, One-Hot Encoding, Count Vectorizer
	2. Statistical: TF-IDF
	3. Word Embeddings: Word2Vec, GloVe, FastText
	4. Document Embeddings: Doc2Vec
	5. Advanced: Sentence Transformers (e.g., BERT-based models)
5. Similarity
	1. Vector similarity
	2. Euclidean distance
	3. Dot product Similarity
	4. Cosine Similarity
	5. Jaccard Similarity
	6. Manhattan Distance
6. How to implement a production AI application?
	1. Prompts
	2. RAG - give it documents/data and then ask questions
	3. pre-train the foundation model on the dataset to give more accurate results
7. LLM - large language model
	1. Foundation models: pre-trained by majorcompanies on general purpose data trained on huge data, and have billions of parameters (the more the merrier) (7b, 13b, 34b, 70b, 100b+)
	2. Fine-tuning: Customize a base model on your dataset
	3. Inference model: model which is deployed in production
	4. Quantization - lossy compression (16bit -> 8bit -> 4bit)
	5. Tokenization -> breaks words to fit into the model => more context more tokens -> this is how you pay for using models
	6. Inference parameters: Temperature, Top K, Top P, Response length, Penalties, Stop sequences
	7. Popular LLMs: OpenAI, Claude, DeepSeek, Mistral, Llama, Qwen, Gemini, Grok, Phi
	8. Deploment tools: Llamma.cpp, Ollama
	9. Production: OpenAI, Azure, Amazon Bedrock, Google Vertex, AWS EC2, EKS, Azure AKS and onprem
	10. Front-end chat: open-webui, librechat
	11. RAG: Langchain, Llamaindex, 
	12. Agent AI: PydanticAI, Langgraph
	13. FineTuning: unsloth 
	14. Monitoring and Observability: Token usage, Latency, Error rates, Prompt version changes, Retrieval quality, User feedback: litellm, langsmith
8. Strategies: 
	1. Cite sources explicitly 
	2. Second LLM/verifier model: does fact check from output of previous model
	3. Cross-model consistency: get output from multiple models and compare
	4. Prompting
	5. Confidence score, temperature tweaks
	6. human in the loop - with subject matter expert to review and collect feedback
	7. Monitor and analytics: User feedback, re-index data 