---
layout: post
title: ML
date: 2025-06-16 00:26 -0500
author: nooneswarup
categories: [ML]
tags: [AI, ML]  
---

First we need to have a problem statement and clear set of desired outcomes. 
Then we follow these steps to get our results.
# 1. Data Collection
1. Type of data needed (numerical, categorical, text, images).
2. Data sourcing 
	- Internal databases (CRM systems, transaction logs)
	- External sources (e.g., public datasets, APIs, web scraping).
	- Third-party providers or data vendors.​
3. Ensure Data compliance and Privacy and other regulations. (GDPR, HIPAA etc.)
4. Store data and Document collection process.
5. Explore the DataFrames by .head(), .describe(), and .info() to get a high-level overview.
# 2. Data cleaning
1. What is data cleaning and how to do it?
	Data cleaning is the process of preparing your dataset by identifying and correcting or removing errors, inconsistencies, and inaccuracies. This ensures that the data is accurate, complete, and ready for analysis or modeling.​
	
2. Why Data Cleaning Matters? 
	Clean data is essential for accurate reporting, reliable analysis, and informed decision-making and business intelligence. 

Data Cleaning Checklist
1. Missing or Null Data 
	- Identify missing values.
	- decide whether to drop records or fill them using methods like mean, median, or mode.
2. Duplicate Data 
	- Detect repeated records.
	- Remove duplicates to prevent skewed analysis.
3. Data format standardization 
	- Ensure consistency in data types (e.g., integers, strings, dates).
	- standardize formats for phone numbers, email addresses, and other fields.
4. Outdated Data
	- Identify data that is no longer relevant.
	- Remove or archive outdated records.
5. Outliers
	- Detect outliers using methods like Interquartile Range (IQR) or Z-score.
	- Decide on handling strategies based on the context and impact.
6. Standardize Text Data 
	- Convert text to a consistent case (e.g., all lowercase).
	- Apply naming conventions and correct syntax or grammatical errors.
7. Data Entry Errors
	- Use validation rules to prevent incorrect entries.
	- Correct spelling mistakes and rectify wrong values.​
8. Logical errors 
	- Identify illogical data (e.g., negative ages, future dates).
	- Flag and fix these errors, possibly by defining acceptable ranges.
9. Validation 
	- Ensure data fields contain valid entries (e.g., proper email formats, valid phone numbers).
	- Use regular expressions or validation tools to enforce data integrity.
# 3. Exploratory Data Analysis (EDA)
EDA is a process where we combine quantitative and graphical techniques to provide insights into the data.​ Example: Plotting histograms, or using .groupby
1. Analyze the data's structure and content.
2. Identify patterns, trends, and relationships.
3. Detect anomalies or outliers.
4. Test underlying assumptions.
5. Matplotlib, Seaborn, Plotly for visualizations 
6. Variable Analysis: Univariate, Bivariate, Multivariate 
7. Inspect the data: Pandas (head, tail, info, shape, nunique, describe)
8. Perform Data Transformation:
9. Scaling (Normalization (min-max scaling), Standardization)
10. combine features, create ratios, encoding, handle outliers 
11. Document finding and communicate to stake holders or management.
# 4. Feature Engineering and Selection
Feature Engineering is transforming of raw features into meaningful features that result in improved model performance.
1. Feature creation (Develop new features from existing data to capture additional information)
	Ex: From "date", extract "day of the week" or "month".
2. Feature transformation (Apply mathematical transformations to features )
3. Feature encoding (Convert categorical variables into numerical formats)
	Ex: Use one-hot encoding for nominal categories.
4. Feature scaling (min-max scaling, z-score standardization)
5. Feature selection
# 5. Model Selection
The core of the workflow is choosing the right model for the required task.
1. Supervised - labels
	1. Classification:  predict discrete labels or categories
	2. Regression: predict continuos values
		1. Linear Regression
		2. Logistic Regression
		3. Decision Trees
		4. SVM - Support Vector Machines
		5. K-NN K-Nearest Neighbors
		6. Naive Bayes
		7. Random Forest
		8. Ensemble Learning - combines simple models to create stronger and smarter model (Bagging, Boosting)
2. Unsupervised - no labels
	1. Clustering
	2. Dimensionality Reduction
		1. K-Means Clustering
		2. DBSCAN
		3. PCA
3. Reinforcement Learning - reward based learning
4. Semi-supervised 
# 6. Data Splitting
Data Splitting involves dataset splitting into distinct subsets to train and evaluate your machine learning models. They are:​
1. Train: used to train the model
2. Test: used to assess the model's performance on unseen data
3. Validation: used to fine-tune model params and select the best model

Check list:
1. Common rations: (70-80% train, validation 10-15%, Test 10-15%)
2. Use random splitting 
3. Test dataset should remain unseen by the model or else can skew the performance 
4. Document the splitting process
5. Time-series - doing time-based splitting
6. Stratified K-Fold Cross-Validation

# 7.  Model Training
Model training is the process where a machine learning algorithm learns from data by adjusting its internal parameters to minimize errors in its predictions. This involves feeding the algorithm with training data and allowing it to iteratively improve its performance.
1. Set initial parameters
2. Define the model architecture.
3. Feed the training data into the model and allow it to learn by minimizing the loss function.
4. Monitor training metrics
5. Hyper-parameter tuning 

# 8. Model Evaluation
This process helps determine how well the model generalizes to new, unseen data and guides decisions on model selection, tuning, and deployment.​
1. Classification:
	1. Accuracy
	2. Precision
	3. Recall
	4. F1 Score
	5. ROC-AUC 
	6. Confusion Matrix
2. Regression:
	1. MAE (Mean Absolute Error)
	2. Mean Squared Error (MSE)
	3. Root Mean Squared Error (RMSE)
	4. R-squared (Coefficient of Determination)​
3. Bias: it is the accuracy (value we got from the model - ground truth)
4. Variance: Spread of the data
5. Bias tells how accurate the data is and variance tells how consistent our data is
6. Document  evaluation procedures, metrics used, and results obtained.

An optimal model is one that has the lowest bias and variance and since these two attributes are indirectly proportional, the only way to achieve this is through a tradeoff between the two. 
# 9. Model Deployment
AWS, GCP, Azure 
Containerize (Docker), Add API's 
CI/CD, Git 
Monitoring and logging
Authentication and Authorization 
Testing and Validation
Recovery

# 10. Model Monitoring and Maintenance
 continuously monitor its performance and maintain its effectiveness after deployment is done
 -> Logging, Alerts, Maintenance 
# 11.  more:
Loss functions: measure of model prediction - correctness (predicted - ground truth). The loss function is to capture the difference between the actual and predicted values for a single record 
Cost functions: aggregate the difference for the entire training dataset.
Learning rate -> to achieve convergence LR(0>1) slowly change it

we need to minimize loss so we use optimizers to improve the model by adjusting the weights: we will have to update weights after each epoch (learning rate)

Optimizers:
SGD - stochastic gradient descent
Adam
Momentum
RMSProp
ADAMprop

resources:
https://www.datacamp.com/blog/infographic-data-cleaning-checklist
https://gonulayci.substack.com/p/why-scaling-isnt-the-answer-to-everything
https://builtin.com/articles/feature-engineering
https://www.purestorage.com/knowledge/machine-learning-workflow.html
https://developers.google.com/machine-learning/crash-course/overfitting/dividing-datasets
https://www.v7labs.com/blog/train-validation-test-set
https://www.qwak.com/post/model-deployment
https://microsoft.github.io/code-with-engineering-playbook/machine-learning/ml-model-checklist/
https://sites.google.com/view/datascience-cheat-sheets
https://www.youtube.com/watch?v=i_LwzRVP7bg
https://scikit-learn.org/stable/machine_learning_map.html
https://www.reddit.com/r/learnmachinelearning/comments/qlpcl8/a_clear_roadmap_to_complete_learning_aiml_by_the/
https://en.wikipedia.org/wiki/Precision_and_recall#F-measure
https://www.geeksforgeeks.org/machine-learning-model-evaluation/
https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall
https://neptune.ai/blog/ml-model-evaluation-and-selection
https://gonulayci.substack.com/p/why-scaling-isnt-the-answer-to-everything
